from pydantic import BaseModel
from crewai.flow import Flow, listen, start, router, or_
from litellm import completion
from rag_flow.crews.rag_crew.rag_crew import RagCrew


class Config:
    """
    Configuration class for RAG agent flow.

    Attributes
    ----------
    model_emb : str
        The embedding model to use.
    model : str
        The language model to use.
    path_save_dir : str
        Path to save the answer output.
    topic : str
        The topic to which questions should be relevant.
    """
    model_emb: str = "text-embedding-ada-002"
    model: str = "azure/gpt-4o"
    path_save_dir: str = "./output/answer.md"
    topic: str = "Rivoluzione Francese"

config = Config()

########################################

class RagState(BaseModel):
    """
    State model for the RAG agent flow.

    Attributes
    ----------
    query : str
        The user query.
    answer : str
        The answer generated by the agent.
    """
    query: str = ""
    answer: str = ""


class RagAgentFlow(Flow[RagState]):
    """
    RAG Agent Flow for handling user queries and generating answers.

    This class defines the flow of the RAG agent, including query intake,
    relevance evaluation, answer generation, and answer saving.

    Attributes
    ----------
    input_query : str or None
        The input query from the user.
    """

    input_query = None

    @start("Not Relevant")
    def start_flow(self):
        """
        Entry point for the flow.

        This method is the starting node of the flow. It does not perform any action.
        """
        pass

    @listen(or_(start_flow, "Not Relevant"))
    def get_user_query(self):
        """
        Listen for the start or 'Not Relevant' state and set the user query.

        Sets the state's query attribute to the input query.
        """
        if self.state.query is None:
            self.input_query = input("Enter your question: ")
        self.state.query = self.input_query

    @router(get_user_query)
    def evaluate_question(self):
        """
        Evaluate if the user query is relevant to the configured topic.

        Uses an LLM to determine if the query is relevant. If relevant, routes to 'Relevant';
        otherwise, routes to 'Not Relevant'.

        Returns
        -------
        str
            "Relevant" if the query is relevant, otherwise "Not Relevant".
        """
        response = completion(
            model=config.model,
            messages=[
                {"role": "system",
                 "content": f"You are a judge and you have to check if the query is relevant to the following topic \'{config.topic}\'."
                 "Expected output: respond with a JSON format - not in markdown format - with a single field: {{'is_relevant': True/False}}"},
                {"role": "user",
                 "content": f"Is the following user question relevant to the context: \'{self.state.query}\'?"}
            ]
        )
        response_content = response.choices[0].message["content"]
        answer_json = eval(response_content)
        if answer_json['is_relevant']:
            return "Relevant"
        print("The question is not relevant to the topic.")
        self.state.query = None
        return "Not Relevant"

    @listen("Relevant")
    def rag_answer(self):
        """
        Generate an answer for a relevant query using the RAG crew.

        Invokes the RAG crew to process the query and stores the result in the state.
        """
        result = (
            RagCrew()
            .crew()
            .kickoff(inputs={"query": self.state.query})
        )
        self.state.answer = result.raw

    @listen(rag_answer)
    def save_answer(self):
        """
        Save the generated answer to a file.

        Writes the answer from the state to the configured output file.
        """
        with open(config.path_save_dir, "w") as f:
            f.write(self.state.answer)
        

def kickoff():
    """
    Run the RAG agent flow interactively.

    Prompts the user for a question, sets it as input, and starts the flow.
    """
    rag_agent_flow = RagAgentFlow()
    rag_agent_flow.input_query = input("Enter your question: ")
    rag_agent_flow.kickoff()


def plot():
    """
    Plot the flow diagram of the RAG agent flow.

    Visualizes the flow using the plot method.
    """
    rag_agent_flow = RagAgentFlow()
    rag_agent_flow.plot()


if __name__ == "__main__":
    kickoff()